{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Öffne die JSON-Datei und lade den Inhalt\n",
    "with open('/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/api_token.json', 'r') as api_file:\n",
    "    api_token_file = json.load(api_file)\n",
    "\n",
    "# Extrahiere die Variable aus den Daten\n",
    "api_token = api_token_file['Hugging_face_token']\n",
    "open_ai_token = api_token_file['Open_api_token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory,ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(repo_id='mistralai/Mistral-7B-Instruct-v0.2', huggingfacehub_api_token=api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Where is Langchain?'\n",
    "output = llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are an artificial intelligence assistant, answer the question. {question}\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"How does LangChain make LLM application development easier?\"\n",
    "llm_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set your API Key from OpenAI\n",
    "chat = ChatOpenAI(temperature=0, openai_api_key=open_ai_token)\n",
    "\n",
    "# Create the conversation history and add the first AI message\n",
    "history = ChatMessageHistory()\n",
    "history.add_ai_message(\"Hello! Ask me anything about Python programming!\")\n",
    "\n",
    "# Add the user message to the history and call the model\n",
    "history.add_user_message(\"What is a list comprehension?\")\n",
    "ai_response = chat(history.messages)\n",
    "print(ai_response)\n",
    "\n",
    "# Add another user message and call the model\n",
    "history.add_user_message(\"Describe the same in fewer words\")\n",
    "\n",
    "\n",
    "ai_response = chat(history.messages)\n",
    "print(ai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API Key from OpenAI\n",
    "chat = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0, openai_api_key=open_ai_token)\n",
    "\n",
    "# Define a buffer memory\n",
    "memory = ConversationBufferMemory(size=2)\n",
    "\n",
    "# Define the chain for integrating the memory with the model\n",
    "buffer_chain = ConversationChain(llm=chat, memory=memory, verbose=True)\n",
    "\n",
    "# Invoke the chain with the inputs provided\n",
    "buffer_chain.predict(input=\"Explain what is seaborn in python.\")\n",
    "buffer_chain.predict(input=\"Tell me about Germany something\")\n",
    "buffer_chain.predict(input=\"Tell me about Xbox something.\")\n",
    "buffer_chain.predict(input=\"Tell me about Playstation something.\")\n",
    "buffer_chain.predict(input=\"What was my first question?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API Key from OpenAI\n",
    "chat = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0, openai_api_key=open_ai_token)\n",
    "\n",
    "# Define a summary memory that uses an OpenAI model\n",
    "memory = ConversationSummaryMemory(llm=OpenAI(model_name=\"gpt-3.5-turbo-instruct\", openai_api_key=open_ai_token))\n",
    "\n",
    "# Define the chain for integrating the memory with the model\n",
    "summary_chain = ConversationChain(llm=chat, memory=memory, verbose=True)\n",
    "\n",
    "# Invoke the chain with the inputs provided\n",
    "summary_chain.predict(input=\"Describe the relationship of the human mind with the keyboard when taking a great online class.\")\n",
    "summary_chain.predict(input=\"Use an analogy to describe it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Retrieval Augmented Generation (RAG)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf\")\n",
    "data = loader.load()\n",
    "print(data[36])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third party document loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import HNLoader\n",
    "loader = HNLoader(\"https://news.ycombinator.com/\")\n",
    "data = loader.load()\n",
    "print(data[0])\n",
    "print(data[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Splitting by Charakter**\n",
    "\n",
    "Dieser Code erstellt eine Instanz der CharacterTextSplitter-Klasse und verwendet sie, um einen gegebenen Text in Chunks aufzuteilen.\n",
    "\n",
    "Zuerst wird eine Zeichenkette quote definiert, die den Text enthält, der aufgeteilt werden soll. Dann werden die Variablen chunk_size und chunk_overlap festgelegt, um die Größe der Chunks und die Überlappung zwischen den Chunks anzugeben.\n",
    "\n",
    "Anschließend wird eine Instanz der CharacterTextSplitter-Klasse erstellt und den Variablen chunk_size und chunk_overlap übergeben. Diese Klasse implementiert die Logik zum Aufteilen des Textes in Chunks.\n",
    "\n",
    "Schließlich wird die Methode split_text() der splitter-Instanz aufgerufen, um den Text in Chunks aufzuteilen. Das Ergebnis wird in der Variable docs gespeichert. Schließlich werden die Chunks mit print(docs) ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = 'One machine can do the work of fifty ordinary humans. No machine can do the work of one extraordinary human.'\n",
    "chunk_size = 24\n",
    "chunk_overlap = 3\n",
    "\n",
    "# Create an instance of the splitter class\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap)\n",
    "\n",
    "# Split the document and print the chunks\n",
    "docs = splitter.split_text(quote) \n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = 'Words are flowing out like endless rain into a paper cup,\\nthey slither while they pass,\\nthey slip away across the universe.'\n",
    "chunk_size = 24\n",
    "chunk_overlap = 10\n",
    "\n",
    "# Create an instance of the splitter class\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_overlap = 10,\n",
    "    chunk_size=24\n",
    "\n",
    ")\n",
    "\n",
    "# Split the document and print the chunks\n",
    "docs = splitter.split_text(quote)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/\")\n",
    "data = loader.load()\n",
    "\n",
    "# Define variables\n",
    "chunk_size = 300\n",
    "chunk_overlap = 100\n",
    "\n",
    "# Split the HTML\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=['.'])\n",
    "\n",
    "docs = splitter.split_documents(data)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API Key from OpenAI\n",
    "openai_api_key = open_ai_token\n",
    "\n",
    "loader = PyPDFLoader('/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf')\n",
    "data = loader.load()\n",
    "print(data[89]) ## seite 74\n",
    "chunk_size = 200\n",
    "chunk_overlap = 50\n",
    "\n",
    "# Split the quote using RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap)\n",
    "docs = splitter.split_documents(data) \n",
    "docs\n",
    "# Define an OpenAI embeddings model\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=open_ai_token)\n",
    "\n",
    "# Create the Chroma vector DB using the OpenAI embedding function; persist the database\n",
    "vectordb = Chroma(\n",
    "    persist_directory='embedding/chroma/',\n",
    "    embedding_function=embedding_model)\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API Key from OpenAI\n",
    "\n",
    "loader = PyPDFLoader('/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf')\n",
    "data = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50,\n",
    "    separators=['.'])\n",
    "docs = splitter.split_documents(data) \n",
    "\n",
    "# Embed the documents and store them in a Chroma DB\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "docstorage = Chroma.from_documents(docs, embedding_model)\n",
    "\n",
    "# Define the Retrieval QA Chain to integrate the database and LLM\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0, openai_api_key=openai_api_key),         chain_type=\"stuff\", retriever=docstorage.as_retriever())\n",
    "\n",
    "# Run the chain on the query provided\n",
    "query = \"what is the third chapter of storytelling-with-data-cole-nussbaumer-knaflic called?\"\n",
    "print(qa.invoke(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API Key from OpenAI\n",
    "\n",
    "loader = PyPDFLoader('/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/PR_Ricca.pdf')\n",
    "data = loader.load()\n",
    "data\n",
    "# print(data[1])\n",
    "# splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=200,\n",
    "#     chunk_overlap=50,\n",
    "#     separators=['.'])\n",
    "# docs = splitter.split_documents(data) \n",
    "\n",
    "# embedding_model = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "# docstorage = Chroma.from_documents(docs, embedding_model)\n",
    "\n",
    "# # Define the function for the question to be answered with\n",
    "# qa = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "#     OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0, \n",
    "#            openai_api_key=openai_api_key), chain_type=\"stuff\", \n",
    "#            retriever=docstorage.as_retriever()\n",
    "# )\n",
    "\n",
    "# # Run the query on the documents\n",
    "# results = qa({\"question\": \"Which models does he explain in the first pages?\"}, return_only_outputs=True)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import HuggingFaceHub\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Setze die Repository-ID für Mistral-7B-Instruct\n",
    "repo_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "\n",
    "# Erstelle eine Instanz von HuggingFaceHub\n",
    "llm = HuggingFaceHub(repo_id=repo_id, huggingfacehub_api_token=api_token)\n",
    "\n",
    "# Lade nur die Seite 5 des PDF-Dokuments\n",
    "loader = PyPDFLoader(\"/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf\")\n",
    "page_number = 5\n",
    "data = loader.load_page(page_number)\n",
    "\n",
    "# Erstelle eine Instanz von HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='bert-base-uncased')  # Beispiel-Modellname, anpassen nach Bedarf\n",
    "\n",
    "# Generiere die Einbettungen für die geladene Seite\n",
    "embeddings = embedding_model.embed_text(data)\n",
    "\n",
    "\n",
    "# # Definiere die Größe der Abschnitte für den Splitter\n",
    "# chunk_size = 200\n",
    "# chunk_overlap = 50\n",
    "\n",
    "# # Teile den Text mit RecursiveCharacterTextSplitter\n",
    "# splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=chunk_size,\n",
    "#     chunk_overlap=chunk_overlap)\n",
    "# docs = splitter.split_documents(data) \n",
    "\n",
    "# # Erstelle eine Instanz von HuggingFaceEmbeddings\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name='bert-base-uncased')  # Beispiel-Modellname, anpassen nach Bedarf\n",
    "\n",
    "# # Verwende die Embedding-Methode von HuggingFaceEmbeddings\n",
    "# embeddings = embedding_model.embed_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecursiveCharacterTextSplitter\n",
    "\n",
    "- Unterteil ein Text in 300 Chunks. Ein Chunk ist ein Charakter eines Wortes das heißt es werden 300 Zeichen aus der Textpassage genommen.\n",
    "- Weiterhin setzten wir die Größe des Overlaps auf 100 Zeichen. Das heißt das von einem Chunk zum anderen Chunk 100 Zeichen überlappen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50, \n",
    "    length_function = len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **filepath = '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/PR_Ricca.pdf':** Hier wird der Pfad zur PDF-Datei festgelegt, die gelesen werden soll.\n",
    "\n",
    "- **loader = PyPDFLoader(filepath):** Hier wird eine Instanz der PyPDFLoader-Klasse erstellt, die zum Laden von PDF-Dateien verwendet wird. Der Pfad zur PDF-Datei wird als Argument an den Konstruktor der Klasse übergeben.\n",
    "\n",
    "- **chunks = loader.load_and_split(text_splitter=text_splitter):** Die Methode load_and_split der PyPDFLoader-Instanz wird aufgerufen, um die PDF-Datei zu laden und ihren Inhalt in Chunks aufzuteilen. Der text_splitter, der zuvor als Instanz der RecursiveCharacterTextSplitter-Klasse erstellt wurde, wird als Argument an die Methode übergeben und bestimmt, wie der Text in Chunks aufgeteilt wird. Die aufgeteilten Chunks werden in der Variable chunks gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf'\n",
    "loader = PyPDFLoader(filepath)\n",
    "chunks = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Display Chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page content: \n",
      " to the narrative order and flow in Chapter 7.\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 47}\n",
      "----------------------------\n",
      "Page content: \n",
      " In closing  33\n",
      "Figu Re 1.2  Example storyboard\n",
      "In closing\n",
      "When it comes to explanatory analysis, being able to concisely artic-\n",
      "ulate exactly who you want to communicate to and what you want \n",
      "to convey before you start to build content reduces iterations and \n",
      "helps ensure that the communication you build meets the intended \n",
      "purpose. Understanding and employing concepts like the 3‐minute \n",
      "story, the Big Idea, and storyboarding will enable you to clearly and \n",
      "succinctly tell your story and identify the desired flow.\n",
      "While pausing before actually building the communication might feel \n",
      "like it’s a step that slows you down, in fact it helps ensure that you \n",
      "have a solid understanding of what you want to do before you start \n",
      "creating content, which will save you time down the road.\n",
      "With that, consider your first lesson learned. You now understand \n",
      "the importance of context .\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 48}\n",
      "----------------------------\n",
      "Page content: \n",
      " 35chapter two\n",
      "choosing an effective \n",
      "visual\n",
      "There are many different graphs and other types of visual displays of \n",
      "information, but a handful will work for the majority of your needs. \n",
      "When I look back over the 150+ visuals that I created for workshops \n",
      "and consulting projects in the past year, there were only a dozen dif-\n",
      "ferent types of visuals that I used (Figure 2.1). These are the visuals \n",
      "we’ll focus on in this chapter.\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 50}\n",
      "----------------------------\n",
      "Page content: \n",
      " 36 choosing an effective visual\n",
      "Simple te xt Scatterplot\n",
      "LineCategory 2Category 1 1 5% 22% 42%\n",
      "40% 36% 20%\n",
      "Category 3\n",
      "SlopegraphTable\n",
      "HeatmapCategory 1 15%\n",
      "Category 4 30% 29% 26%22% 42%\n",
      "Category 2 40% 36% 20%\n",
      "Category 3 35% 17% 34%B C A\n",
      "Category 5 55% 30% 58%\n",
      "Category 6 11% 25% 49%Category 6 1 1% 25% 49%Category 5 55% 30% 58%A B C\n",
      "Category 4 30% 29% 26%35% 17% 34%91%\n",
      "Figure 2.1  The visuals I use most\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 51}\n",
      "----------------------------\n",
      "Page content: \n",
      " choosing an effective visual  37\n",
      "  Vertical bar Horizontal bar\n",
      "  Stacked ver tical bar Stacked hor izontal ba r\n",
      "  WaterfallSquar e area\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 52}\n",
      "----------------------------\n",
      "Page content: \n",
      " 38 choosing an effective visual\n",
      "Simple text\n",
      "When you have just a number or two to share, simple text can be a \n",
      "great way to communicate. Think about solely using the number—\n",
      "making it as prominent as possible—and a few supporting words \n",
      "to clearly make your point. Beyond potentially being misleading, \n",
      "putting one or only a couple of numbers in a table or graph simply \n",
      "causes the numbers to lose some of their oomph. When you have \n",
      "a number or two that you want to communicate, think about using \n",
      "the numbers themselves.\n",
      "To illustrate this concept, let’s consider the following example. A \n",
      "graph similar to Figure 2.2 accompanied an April 2014 Pew Research \n",
      "Center report on stay‐at‐home moms.\n",
      "Figure 2.2  Stay‐at‐home moms original graph41\n",
      "20\n",
      "1970 2012Children with a\n",
      "\"Traditional\" Stay-at-\n",
      "Home Mother\n",
      "% of children with a married\n",
      "stay-at-home mother with a\n",
      "working husband\n",
      "Note: Based on children younger than 18. \n",
      "Their mothers are categoriz ed based on  \n",
      "employ ment status in 1970 and 2012.\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 53}\n",
      "----------------------------\n",
      "Page content: \n",
      " employ ment status in 1970 and 2012.\n",
      "Source: Pew Research Center analysis of  \n",
      "March Current Population Survey s \n",
      "Integrated Public Use M icrodata Series \n",
      "(IPUMS-CPS), 1971 and 2013\n",
      "Adapted f rom PEW  RESEARCH CENT ER\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 53}\n",
      "----------------------------\n",
      "Page content: \n",
      " Simple text  39\n",
      "The fact that you have some numbers does not mean that you need \n",
      "a graph! In Figure 2.2, quite a lot of text and space are used for a \n",
      "grand total of two numbers. The graph doesn’t do much to aid in \n",
      "the interpretation of the numbers (and with the positioning of the \n",
      "data labels outside of the bars, it can even skew your perception of \n",
      "relative height such that 20 is less than half of 41 doesn’t really come \n",
      "across visually).\n",
      "In this case, a simple sentence would suffice: 20% of children had \n",
      "a traditional stay‐at‐home mom in 2012, compared to 41% in 1970.\n",
      "Alternatively, in a presentation or report, your visual could look some -\n",
      "thing like Figure 2.3.\n",
      "Figure 2.3  Stay‐at‐home moms simple text makeover20%\n",
      "of childr en had a\n",
      "traditional sta y-at-home mom\n",
      "in 20 12, compar ed to 41% in 1 970\n",
      " \n",
      "As a side note, one consideration in this specific example might be \n",
      "whether you want to show an entirely different metric. For example,\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 54}\n",
      "----------------------------\n",
      "Page content: \n",
      " you could reframe in terms of the percent change: “The number of \n",
      "children having a traditional stay‐at‐home mom decreased more \n",
      "than 50% between 1970 and 2012.” I advise caution, however, any \n",
      "time you reduce from multiple numbers down to a single one—think \n",
      "about what context may be lost in doing so. In this case, I find that \n",
      "the actual magnitude of the numbers (20% and 41%) is helpful in \n",
      "interpreting and understanding the change.\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 54}\n",
      "----------------------------\n",
      "Page content: \n",
      " 40 choosing an effective visual\n",
      "When you have just a number or two that you want to communicate: \n",
      "use the numbers directly.\n",
      "When you have more data that you want to show, generally a table \n",
      "or graph is the way to go. One thing to understand is that people \n",
      "interact differently with these two types of visuals. Let’s discuss each \n",
      "in detail and look at some specific varieties and use cases.\n",
      "Tables\n",
      "Tables interact with our verbal system, which means that we read  \n",
      "them. When I have a table in front of me, I typically have my index \n",
      "finger out: I’m reading across rows and down columns or I’m com-\n",
      "paring values. Tables are great for just that—communicating to a \n",
      "mixed audience whose members will each look for their particular \n",
      "row of interest. If you need to communicate multiple different units \n",
      "of measure, this is also typically easier with a table than a graph.\n",
      "Tables in live presentations\n",
      "Using a table in a live presentation is rarely a good idea.\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 55}\n",
      "----------------------------\n",
      "Page content: \n",
      " As your audience reads it, you lose their ears and atten-\n",
      "tion to make your point verbally. When you find yourself \n",
      "using a table in a presentation or report, ask yourself: what \n",
      "is the point you are trying to make? Odds are that there will \n",
      "be a better way to pull out and visualize the piece or pieces \n",
      "of interest. In the event that you feel you’re losing too much \n",
      "by doing this, consider whether including the full table in the \n",
      "appendix and a link or reference to it will meet your audi-\n",
      "ence’s needs.\n",
      "One thing to keep in mind with a table is that you want the design to \n",
      "fade into the background, letting the data take center stage. Don’t \n",
      "let heavy borders or shading compete for attention. Instead, think\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 55}\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks[79:90]:\n",
    "    print(\"Page content: \\n\", chunk.page_content),\n",
    "    print(\"Page_metadata: \\n\", chunk.metadata),\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector DB \n",
    "## 1. load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Use an open source embedding model to embed the chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In dieser Zeile wird eine Instanz der Klasse SentenceTransformerEmbeddings erstellt. Dies ist ein Modell, das Sätze in Vektoren umwandelt, die ihre semantische Bedeutung repräsentieren. Diese Vektoren werden oft als \"Einbettungen\" oder \"Embeddings\" bezeichnet.\n",
    "\n",
    "- Die SentenceTransformerEmbeddings-Klasse verwendet die SentenceTransformer-Bibliothek, um Einbettungen für Texte zu generieren. Die Klasse verwendet ein vortrainiertes Modell, um die Einbettungen zu generieren. Die Einbettungen können dann in einer Chroma-Datenbank gespeichert und für die spätere Verwendung abgerufen werden.\n",
    "\n",
    "- Der Parameter model_name=\"all-MiniLM-L6-v2\" gibt an, welches vortrainierte Modell verwendet werden soll. In diesem Fall wird das Modell \"all-MiniLM-L6-v2\" verwendet, das ein kleines, aber leistungsfähiges Modell für die Erzeugung von Satzeinbettungen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardo/anaconda3/envs/llm_train/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05895749852061272, 0.05387335643172264, 0.008316715247929096, 0.0206805057823658, 0.0022009313106536865, -0.034434445202350616, 0.08473188430070877, 0.1077682226896286, 0.058957234025001526, -0.016638653352856636, 0.06211813539266586, -0.0740492045879364, -0.0303032286465168, 0.03807591274380684, -0.004251338075846434, -0.007986415177583694, 0.0031452886760234833, -0.07220274955034256, -0.01501194667071104, -0.07136189937591553, -0.08817413449287415, 0.0452018640935421, 0.009071135893464088, 0.041956428438425064, -0.0012928870273754, -0.014840386807918549, -0.03942627087235451, 0.007077477872371674, -0.036413680762052536, -0.042899180203676224, -0.04982227832078934, 0.009418361820280552, -0.022699205204844475, 0.010238043032586575, -0.00445396825671196, -0.07801611721515656, -0.070695661008358, -0.005806431174278259, 0.03875807300209999, 0.01204211637377739, -0.05325385555624962, -0.0963793396949768, -0.028097203001379967, -0.009883742779493332, 0.06731418520212173, 0.004278208594769239, 0.02124866470694542, -0.022914476692676544, -0.06625277549028397, -0.02348857931792736, 4.158759111305699e-05, 0.00964048970490694, -0.03294288367033005, 0.014496402814984322, 0.018593674525618553, 0.047485243529081345, -0.012361058965325356, 0.03878827765583992, 0.02369307167828083, -0.06135307252407074, -0.002361031249165535, -0.03253591060638428, -0.11364953964948654, 0.06236247345805168, 0.059831637889146805, 0.08645803481340408, -0.022679559886455536, 0.03328515589237213, 0.016969120129942894, -0.04824632778763771, -0.010130156762897968, -0.0021239817142486572, -0.06585216522216797, -0.04025018960237503, -0.021393608301877975, -0.02657456323504448, 0.046205248683691025, -0.044886842370033264, 0.034001607447862625, 0.05156944692134857, -0.006135378964245319, 0.001145144458860159, -0.09618978202342987, 0.029961099848151207, -0.007510695140808821, 0.015603425912559032, -0.042808204889297485, 0.043429456651210785, -0.019901875406503677, 0.07665636390447617, -0.01384327095001936, 0.034392017871141434, 0.07292252033948898, 0.0133975213393569, -0.07558221369981766, -0.03218085318803787, -0.05393291264772415, -0.016610195860266685, -0.10869736224412918, 0.23937205970287323, -0.020459236577153206, 0.014236437156796455, 0.02164141833782196, 0.09602873772382736, -0.010307742282748222, 0.01200162898749113, -0.018780171871185303, -0.04145337641239166, 0.048597563058137894, -0.005922127515077591, -0.06287381052970886, -0.03733189404010773, 0.013004820793867111, -0.009868098422884941, 0.048202723264694214, -0.02079993113875389, -0.08003193140029907, 0.005167827010154724, 0.00725804315879941, -0.014367008581757545, 0.06591780483722687, 0.04329393804073334, -0.06329438835382462, 0.014587262645363808, -0.003063279204070568, -0.03614052012562752, 0.03620026260614395, -4.612938114318177e-33, 0.0409914031624794, 0.004939346108585596, -0.006083912216126919, 0.043096765875816345, 0.0167239923030138, 0.09288540482521057, -0.03938951715826988, 0.004293610341846943, -0.05639263615012169, 0.0672842413187027, -0.16096237301826477, -0.0779045820236206, -0.03543432056903839, 0.0018369597382843494, 0.06707488000392914, 0.028946315869688988, 0.03300480917096138, 0.029375018551945686, -0.0051882704719901085, -0.027864258736371994, -0.01788497157394886, 0.1109727993607521, -0.04470197111368179, 0.04207243770360947, 0.011976080946624279, -0.08128233253955841, 0.008002789691090584, -0.07154875248670578, -0.06217927113175392, 0.033613819628953934, -0.01154992263764143, 0.027502810582518578, -0.07996906340122223, 0.002480847528204322, 0.02366090752184391, -0.09160154312849045, 0.06299559026956558, -0.004837492015212774, -0.0030987428035587072, -0.024675210937857628, 0.08662998676300049, 0.024653417989611626, -9.652456355979666e-05, -0.03318057581782341, -0.009754078462719917, 0.08528172969818115, 0.09049248695373535, -0.005956639070063829, 0.011446849443018436, 0.042310360819101334, 0.0035262685269117355, -0.01033497042953968, -0.07504887878894806, -0.012202832847833633, 0.03234664723277092, 0.025926638394594193, 0.019049691036343575, -0.012024185620248318, 0.05401187390089035, 0.01013104896992445, 0.04285314679145813, -0.040263108909130096, 0.013790000230073929, -0.06209595873951912, -0.009781830944120884, -0.033753663301467896, -0.02063378319144249, -0.03565194085240364, 0.05844387784600258, -0.0428612157702446, -0.05484124273061752, 0.0035845881793648005, 0.0965285524725914, -0.039651673287153244, -0.008388887159526348, -0.02007421851158142, 0.018253538757562637, 0.030845442786812782, -0.003916537389159203, -0.03722589462995529, -0.03793429955840111, -0.0366276390850544, 0.040177375078201294, 0.025641752406954765, 0.050752341747283936, 0.009178625419735909, 0.015644922852516174, -0.05116970092058182, 0.026423173025250435, -0.04617452621459961, -0.11185549944639206, 0.04559491202235222, 0.005629034712910652, 0.04989961162209511, 0.01582547090947628, 4.343787009520321e-33, -0.04824649542570114, 0.05515504628419876, -0.03658045455813408, 0.07717882096767426, -0.04245702549815178, -0.01731182262301445, -0.027591269463300705, 0.05471985787153244, 0.016260158270597458, 0.04789765179157257, 0.07744024693965912, -0.10876806825399399, 0.008191938512027264, -0.056485943496227264, 0.0007533782045356929, -0.019367031753063202, 0.06802394241094589, -0.018168283626437187, -0.07287456095218658, 0.0047272080555558205, -0.08330320566892624, -0.07571673393249512, -0.041829537600278854, 0.023495955392718315, -0.06861050426959991, 0.1004837229847908, -0.024190634489059448, 0.10863713920116425, -0.013029152527451515, 0.0865088626742363, 0.04757517948746681, -0.08774615824222565, -0.00682770274579525, 0.03047875314950943, 0.02873203717172146, 0.20470963418483734, 0.09231504052877426, 0.016746576875448227, -0.00757240504026413, 0.0051491581834852695, 0.042321279644966125, -0.025120457634329796, 0.02354445494711399, 0.13627475500106812, -0.04834604263305664, -0.012725894339382648, -0.004134716931730509, -0.007316081319004297, 0.08094491809606552, 0.030172914266586304, 0.025221839547157288, 0.03171887993812561, -0.025279255583882332, -0.05385499447584152, -0.017319928854703903, 0.02615794911980629, 0.03106723353266716, -0.018321603536605835, -0.03890589624643326, -0.024325508624315262, 0.03653610870242119, 0.018517831340432167, -0.004494012799113989, 0.060770463198423386, -0.008643320761620998, -0.034977179020643234, -0.04582889750599861, -0.018905285745859146, 0.005996147636324167, -0.01612183451652527, 0.06939784437417984, 0.003852604888379574, -0.0701839029788971, -0.08292588591575623, -0.026484305039048195, -0.08900762349367142, -0.022247757762670517, -0.013534908182919025, 0.0385512076318264, -0.039532650262117386, -0.05805931240320206, 0.019006885588169098, 0.0005042309057898819, -0.06959947198629379, -0.043609146028757095, 0.03509559854865074, 0.05783523619174957, -0.014005331322550774, -0.028270576149225235, 0.043782323598861694, -0.012300968170166016, 0.06069758161902428, 0.09069006890058517, -0.01602812483906746, 0.006933591794222593, -1.5034773426236825e-08, 0.05863410234451294, -0.024170150980353355, -0.026048174127936363, 0.06980574876070023, 0.06045081093907356, 0.006414224859327078, -0.05531464144587517, 0.012504199519753456, 0.04093146324157715, 0.028846364468336105, 0.01760147511959076, 0.005015002563595772, 0.023594560101628304, 0.0516316257417202, 0.0250548105686903, -0.05722063407301903, -0.12157945334911346, -0.00018272407760377973, -0.022113293409347534, -0.08405864983797073, -0.026487981900572777, 0.015580772422254086, -2.8786578695871867e-05, 0.023379845544695854, 0.0061817290261387825, 0.047046516090631485, -0.1017637699842453, 0.07688648253679276, 0.09898848831653595, -0.015477916225790977, 0.008368835784494877, 0.043241195380687714, -0.0442679338157177, 0.02451329305768013, -0.037223149091005325, -0.04206930100917816, -0.01472825463861227, 0.026079634204506874, -0.015963831916451454, 0.1360192447900772, -0.05150851234793663, 0.022148428484797478, 0.027097739279270172, -0.0014352109283208847, -0.06500371545553207, -0.020484279841184616, -0.04887637495994568, 0.0839962512254715, -0.0072325654327869415, -0.020550437271595, -0.06095936894416809, 0.06612943112850189, -0.00011498568346723914, 0.05219540372490883, 0.07801417261362076, 0.017105529084801674, 0.09189657866954803, 0.02236110344529152, -0.07054458558559418, 0.05508328601717949, 0.17235015332698822, -0.004390910267829895, 0.011533830314874649, -0.025606105104088783]\n",
      "Dimension of Embedding:  384\n"
     ]
    }
   ],
   "source": [
    "embedding = embedding_function.embed_documents(\"This is a test sentence.\")\n",
    "\n",
    "print(embedding[0])\n",
    "print(\"Dimension of Embedding: \", len(embedding[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload to Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chroma is an open source vector database capable of storing collections of documents along with their metadata, creating embeddings for documents and queries, and searching the collections filtering by document metadata or content. Additionally, Chroma supports multi-modal embedding functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(chunks, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks in DB: 526\n"
     ]
    }
   ],
   "source": [
    "print(\"Chunks in DB:\", db._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Retrieval from Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='to the narrative order and flow in Chapter 7.', metadata={'page': 47, 'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf'}),\n",
       " Document(page_content='attempt to deal with this incident typically leads to a more dramatic \\nsituation. This is known as the first turning point. The first turning \\npoint ensures that life will never be the same for the main charac-\\nter and raises the dramatic question—framed in terms of the main \\ncharacter’s call to action—to be answered in the climax of the play. \\nThis marks the end of the first act.\\nThe second act makes up the bulk of the story. It depicts the main \\ncharacter’s attempt to resolve the problem created through the first \\nturning point. Often, the main character lacks the skills to deal with \\nthe problem he faces, and, as a result, finds himself encountering \\nincreasingly worsening situations. This is known as the character arc, \\nwhere the main character goes through major changes in his life as a \\nresult of what is happening. He may have to learn new skills or reach \\na higher sense of awareness of who he is and what he is capable of \\nin order to deal with his situation.', metadata={'page': 182, 'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf'}),\n",
       " Document(page_content='emphasizing one line at a \\ntime, 229–230\\nseparating spatially, 230–232\\nSpears, Libby, 168\\nStacked bars\\nhorizontal, 161–162\\nleveraging positive and \\nnegative, 158\\n100%, 156–158\\nStoryboarding, 31–33\\nStorytelling, 16, 165–185\\nconstructing the story,  \\n171–174\\nbeginning, 171–173\\nend, 174\\nmiddle, 173–174\\nlessons in, 16\\nmagic of story, 166–171\\nin cinema, 168–170\\nin plays, 167–168\\nin written word, 170–171\\nnarrative structure, 175–179\\nnarrative flow, 175', metadata={'page': 280, 'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf'}),\n",
       " Document(page_content='in order to deal with his situation.\\nThe third act resolves the story and its subplots. It includes a climax, \\nwhere the tensions of the story reach the highest point of intensity. \\nFinally, the dramatic question introduced in the first act is answered,', metadata={'page': 182, 'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Give me the first chapter name.\"\n",
    "retriever = db.as_retriever()\n",
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Connect to LLM (OpenAI )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- openai_api_key=open_ai_token: Der API-Schlüssel für den Zugriff auf die OpenAI API.\n",
    "\n",
    "- model_name=\"gpt-3.5-turbo\": Der Name des zu verwendenden Modells.\n",
    "\n",
    "- temperature=0.0: Die \"Temperatur\" des Modells, die die Zufälligkeit der generierten Texte steuert. Ein Wert von 0.0 bedeutet, dass das - Modell immer die wahrscheinlichste Fortsetzung wählt.\n",
    "\n",
    "- max_tokens=100: Die maximale Anzahl von Tokens, die das Modell generieren soll.\n",
    "\n",
    "\n",
    "**- Was sind Tokens:**\n",
    "\n",
    "In der Textverarbeitung bezeichnet ein Token im Allgemeinen ein Stück eines größeren Textes, das als einzelne Einheit behandelt wird. Ein Token könnte ein Wort, ein Satzzeichen oder sogar ein einzelnes Zeichen sein, abhängig von der spezifischen Tokenisierungsmethode, die verwendet wird. In Ihrem Codebeispiel legt max_tokens=100 die maximale Anzahl von Tokens fest, die das Modell generieren soll. Das bedeutet, dass das Modell nicht mehr als 100 Tokens generieren wird, unabhängig davon, wie viele Wörter oder Zeichen das sind.\n",
    "\n",
    "**- Temperatures:**\n",
    "\n",
    "Bei der Textgenerierung steuert die \"Temperatur\" die Zufälligkeit der generierten Texte. Ein höherer Temperaturwert führt zu zufälligeren Texten, während ein niedrigerer Temperaturwert dazu führt, dass das Modell eher die wahrscheinlichsten Fortsetzungen wählt. In Ihrem Codebeispiel ist temperature=0.0 gesetzt, was bedeutet, dass das Modell immer die wahrscheinlichste Fortsetzung wählen wird. Dies kann dazu führen, dass die generierten Texte konsistenter, aber auch weniger vielfältig sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardo/anaconda3/envs/llm_train/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# llm = ChatOpenAI(\n",
    "#     openai_api_key= open_ai_token,\n",
    "#     model_name = \"gpt-3.5-turbo\",\n",
    "#     temperature = 0.0,\n",
    "#     max_tokens = 100\n",
    "# )\n",
    "\n",
    "llm = HuggingFaceHub(repo_id='mistralai/Mistral-7B-Instruct-v0.2', \n",
    "                     huggingfacehub_api_token=api_token,  \n",
    "                     model_kwargs={\"max_length\": 100})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Connect Vector DB to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",  \n",
    "    retriever = retriever\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 RAG QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardo/anaconda3/envs/llm_train/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the title of the book.',\n",
       " 'answer': 'Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \\nIf you don\\'t know the answer, just say that you don\\'t know. Don\\'t try to make up an answer.\\nALWAYS return a \"SOURCES\" part in your answer.\\n\\n',\n",
       " 'sources': \"Which state/country's law governs the interpretation of the contract?\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the title of the book.\"\n",
    "qa_with_sources(query)\n",
    "llm_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

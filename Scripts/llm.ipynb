{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Öffne die JSON-Datei und lade den Inhalt\n",
    "with open('/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/api_token.json', 'r') as api_file:\n",
    "    api_token_file = json.load(api_file)\n",
    "\n",
    "# Extrahiere die Variable aus den Daten\n",
    "api_token = api_token_file['Hugging_face_token']\n",
    "open_ai_token = api_token_file['Open_api_token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory,ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardo/anaconda3/envs/llm_train/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "/Users/riccardo/anaconda3/envs/llm_train/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceHub(repo_id='mistralai/Mistral-7B-Instruct-v0.2', huggingfacehub_api_token=api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Where is Langchain?'\n",
    "output = llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where is Langchain?\n",
      "\n",
      "Langchain is a decentralized language learning platform built on the Ethereum blockchain. It is not a physical location, but rather a digital ecosystem where users can access language learning resources, connect with language partners, and earn rewards for their learning progress.\n",
      "\n",
      "How does Langchain work?\n",
      "\n",
      "Langchain uses smart contracts to facilitate language learning and reward users for their progress. Users can access a variety of language learning resources, such as videos, articles, and interactive exercises,\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are an artificial intelligence assistant, answer the question. {question}\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How does LangChain make LLM application development easier?',\n",
       " 'text': 'You are an artificial intelligence assistant, answer the question. How does LangChain make LLM application development easier?\\n\\nLangChain is a language model chain that utilizes multiple language models to generate more accurate and contextually relevant responses. It makes LLM (Large Language Model) application development easier in several ways:\\n\\n1. Improved Accuracy: By chaining multiple language models, LangChain can generate more accurate responses by leveraging the strengths of each model. This reduces the need for extensive fine-tuning and manual intervention in the development process.\\n2. Contextual Understanding:'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"How does LangChain make LLM application development easier?\"\n",
    "llm_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardo/anaconda3/envs/llm_train/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/riccardo/anaconda3/envs/llm_train/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"A list comprehension is a concise way to create lists in Python. It allows you to create a new list by applying an expression to each item in an existing iterable (such as a list, tuple, or range) and filtering the items based on a condition.\\n\\nHere's a simple example of a list comprehension that creates a list of squared numbers from 0 to 9:\\n\\n```python\\nsquared_numbers = [x**2 for x in range(10)]\\nprint(squared_numbers)\\n```\\n\\nThis will output:\\n\\n```\\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\\n```\\n\\nList comprehensions are a powerful and concise way to work with lists in Python and are often preferred over traditional for loops for their readability and simplicity.\"\n",
      "content='List comprehension is a concise way to create lists in Python by applying an expression to each item in an iterable.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set your API Key from OpenAI\n",
    "chat = ChatOpenAI(temperature=0, openai_api_key=open_ai_token)\n",
    "\n",
    "# Create the conversation history and add the first AI message\n",
    "history = ChatMessageHistory()\n",
    "history.add_ai_message(\"Hello! Ask me anything about Python programming!\")\n",
    "\n",
    "# Add the user message to the history and call the model\n",
    "history.add_user_message(\"What is a list comprehension?\")\n",
    "ai_response = chat(history.messages)\n",
    "print(ai_response)\n",
    "\n",
    "# Add another user message and call the model\n",
    "history.add_user_message(\"Describe the same in fewer words\")\n",
    "\n",
    "\n",
    "ai_response = chat(history.messages)\n",
    "print(ai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Explain what is seaborn in python.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Explain what is seaborn in python.\n",
      "AI:  Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for creating attractive and informative statistical graphics. It is built on top of matplotlib and integrates closely with pandas data structures. Seaborn offers a variety of plot types, including scatter plots, line plots, bar charts, histograms, and heatmaps. It also has built-in support for visualizing categorical data and time series data. Seaborn is widely used in data science and machine learning projects for exploratory data analysis and communicating insights.\n",
      "Human: Tell me about Germany something\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Explain what is seaborn in python.\n",
      "AI:  Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for creating attractive and informative statistical graphics. It is built on top of matplotlib and integrates closely with pandas data structures. Seaborn offers a variety of plot types, including scatter plots, line plots, bar charts, histograms, and heatmaps. It also has built-in support for visualizing categorical data and time series data. Seaborn is widely used in data science and machine learning projects for exploratory data analysis and communicating insights.\n",
      "Human: Tell me about Germany something\n",
      "AI:  Germany is a country located in central-western Europe. It has a population of over 83 million people and is the most populous country in the European Union. The official language is German, and the currency is the Euro. Germany has a rich history and is known for its contributions to science, philosophy, and the arts. It is also a major economic power, with a strong manufacturing sector and a highly skilled workforce. Some famous landmarks in Germany include the Brandenburg Gate, the Cologne Cathedral, and Neuschwanstein Castle. The country is also known for its delicious cuisine, including dishes such as bratwurst, sauerkraut, and schnitzel.\n",
      "Human: Tell me about Xbox something.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Explain what is seaborn in python.\n",
      "AI:  Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for creating attractive and informative statistical graphics. It is built on top of matplotlib and integrates closely with pandas data structures. Seaborn offers a variety of plot types, including scatter plots, line plots, bar charts, histograms, and heatmaps. It also has built-in support for visualizing categorical data and time series data. Seaborn is widely used in data science and machine learning projects for exploratory data analysis and communicating insights.\n",
      "Human: Tell me about Germany something\n",
      "AI:  Germany is a country located in central-western Europe. It has a population of over 83 million people and is the most populous country in the European Union. The official language is German, and the currency is the Euro. Germany has a rich history and is known for its contributions to science, philosophy, and the arts. It is also a major economic power, with a strong manufacturing sector and a highly skilled workforce. Some famous landmarks in Germany include the Brandenburg Gate, the Cologne Cathedral, and Neuschwanstein Castle. The country is also known for its delicious cuisine, including dishes such as bratwurst, sauerkraut, and schnitzel.\n",
      "Human: Tell me about Xbox something.\n",
      "AI:  Xbox is a video game console brand created and owned by Microsoft. The first Xbox console was released in 2001, and it has since gone through several iterations, including the Xbox 360 and the current Xbox One. Xbox consoles are known for their high-quality graphics and immersive gaming experiences. They also offer online multiplayer capabilities and a wide range of entertainment options, such as streaming services and music apps. Xbox also has a popular subscription service called Xbox Game Pass, which gives users access to a large library of games for a monthly fee. The brand has a strong following among gamers and continues to release new and innovative products.\n",
      "Human: Tell me about Playstation something.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Explain what is seaborn in python.\n",
      "AI:  Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for creating attractive and informative statistical graphics. It is built on top of matplotlib and integrates closely with pandas data structures. Seaborn offers a variety of plot types, including scatter plots, line plots, bar charts, histograms, and heatmaps. It also has built-in support for visualizing categorical data and time series data. Seaborn is widely used in data science and machine learning projects for exploratory data analysis and communicating insights.\n",
      "Human: Tell me about Germany something\n",
      "AI:  Germany is a country located in central-western Europe. It has a population of over 83 million people and is the most populous country in the European Union. The official language is German, and the currency is the Euro. Germany has a rich history and is known for its contributions to science, philosophy, and the arts. It is also a major economic power, with a strong manufacturing sector and a highly skilled workforce. Some famous landmarks in Germany include the Brandenburg Gate, the Cologne Cathedral, and Neuschwanstein Castle. The country is also known for its delicious cuisine, including dishes such as bratwurst, sauerkraut, and schnitzel.\n",
      "Human: Tell me about Xbox something.\n",
      "AI:  Xbox is a video game console brand created and owned by Microsoft. The first Xbox console was released in 2001, and it has since gone through several iterations, including the Xbox 360 and the current Xbox One. Xbox consoles are known for their high-quality graphics and immersive gaming experiences. They also offer online multiplayer capabilities and a wide range of entertainment options, such as streaming services and music apps. Xbox also has a popular subscription service called Xbox Game Pass, which gives users access to a large library of games for a monthly fee. The brand has a strong following among gamers and continues to release new and innovative products.\n",
      "Human: Tell me about Playstation something.\n",
      "AI:  Playstation is a video game console brand created and owned by Sony Interactive Entertainment. The first Playstation console was released in 1994, and it has since become one of the most popular and successful gaming brands in the world. The current console, Playstation 5, was released in 2020 and offers advanced graphics and immersive gameplay. Playstation also has a strong online community and offers a variety of exclusive games, such as the popular franchises God of War and Uncharted. The brand also has a subscription service called Playstation Plus, which gives users access to online multiplayer and free monthly games. Playstation has a loyal fan base and continues to be a major player in the gaming industry.\n",
      "Human: What was my first question?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Your first question was \"Explain what is seaborn in python.\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set your API Key from OpenAI\n",
    "chat = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0, openai_api_key=open_ai_token)\n",
    "\n",
    "# Define a buffer memory\n",
    "memory = ConversationBufferMemory(size=2)\n",
    "\n",
    "# Define the chain for integrating the memory with the model\n",
    "buffer_chain = ConversationChain(llm=chat, memory=memory, verbose=True)\n",
    "\n",
    "# Invoke the chain with the inputs provided\n",
    "buffer_chain.predict(input=\"Explain what is seaborn in python.\")\n",
    "buffer_chain.predict(input=\"Tell me about Germany something\")\n",
    "buffer_chain.predict(input=\"Tell me about Xbox something.\")\n",
    "buffer_chain.predict(input=\"Tell me about Playstation something.\")\n",
    "buffer_chain.predict(input=\"What was my first question?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Describe the relationship of the human mind with the keyboard when taking a great online class.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human and AI discuss the relationship between the human mind and the keyboard when taking a great online class. The AI explains that it is one of collaboration and communication, with the keyboard acting as a tool for the human mind to interact with the online class. The keyboard allows for a seamless flow of information and also enhances the learning experience by allowing the human mind to express thoughts and ideas in a written format.\n",
      "Human: Use an analogy to describe it.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sure, I would say the relationship between the human mind and the keyboard in an online class is like a dance between partners. The human mind leads the way, using the keyboard as a tool to communicate and interact with the online class. Just like in a dance, the keyboard allows for a smooth and coordinated flow of information, enhancing the overall experience.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set your API Key from OpenAI\n",
    "chat = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0, openai_api_key=open_ai_token)\n",
    "\n",
    "# Define a summary memory that uses an OpenAI model\n",
    "memory = ConversationSummaryMemory(llm=OpenAI(model_name=\"gpt-3.5-turbo-instruct\", openai_api_key=open_ai_token))\n",
    "\n",
    "# Define the chain for integrating the memory with the model\n",
    "summary_chain = ConversationChain(llm=chat, memory=memory, verbose=True)\n",
    "\n",
    "# Invoke the chain with the inputs provided\n",
    "summary_chain.predict(input=\"Describe the relationship of the human mind with the keyboard when taking a great online class.\")\n",
    "summary_chain.predict(input=\"Use an analogy to describe it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Retrieval Augmented Generation (RAG)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='  Who  21\\nhelp you ensure they hear your message. Second, What do you want \\nyour audience to know or do?  You should be clear how you want your \\naudience to act and take into account how you will communicate to \\nthem and the overall tone that you want to set for your communication.\\nIt’s only after you can concisely answer these first two questions that \\nyou’re ready to move forward with the third: How can you use data \\nto help make your point?\\nLet’s look at the context of who, what, and how in a little more detail.\\nWho\\nYour audience\\nThe more specific you can be about who your audience is, the better \\nposition you will be in for successful communication. Avoid general \\naudiences, such as “internal and external stakeholders” or “anyone \\nwho might be interested”—by trying to communicate to too many \\ndifferent people with disparate needs at once, you put yourself in a \\nposition where you can’t communicate to any one of them as effec-\\ntively as you could if you narrowed your target audience. Sometimes \\nthis means creating different communications for different audi -\\nences. Identifying the decision maker is one way of narrowing your \\naudience. The more you know about your audience, the better posi-\\ntioned you’ll be to understand how to resonate with them and form \\na communication that will meet their needs and yours.\\nYou\\nIt’s also helpful to think about the relationship that you have with \\nyour audience and how you expect that they will perceive you. Will \\nyou be encountering each other for the first time through this com-\\nmunication, or do you have an established relationship? Do they \\nalready trust you as an expert, or do you need to work to establish \\ncredibility? These are important considerations when it comes to ' metadata={'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf', 'page': 36}\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf\")\n",
    "data = loader.load()\n",
    "print(data[36])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third party document loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Bell Labs: An Institute of Creative Technology (2015) (sts10.github.io)' metadata={'source': 'https://news.ycombinator.com/', 'title': 'Bell Labs: An Institute of Creative Technology (2015) (sts10.github.io)', 'link': 'https://sts10.github.io/2015/09/14/bell-labs-the-idea-factory.html', 'ranking': '1.'}\n",
      "{'source': 'https://news.ycombinator.com/', 'title': 'Bell Labs: An Institute of Creative Technology (2015) (sts10.github.io)', 'link': 'https://sts10.github.io/2015/09/14/bell-labs-the-idea-factory.html', 'ranking': '1.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import HNLoader\n",
    "loader = HNLoader(\"https://news.ycombinator.com/\")\n",
    "data = loader.load()\n",
    "print(data[0])\n",
    "print(data[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Splitting by Charakter**\n",
    "\n",
    "Dieser Code erstellt eine Instanz der CharacterTextSplitter-Klasse und verwendet sie, um einen gegebenen Text in Chunks aufzuteilen.\n",
    "\n",
    "Zuerst wird eine Zeichenkette quote definiert, die den Text enthält, der aufgeteilt werden soll. Dann werden die Variablen chunk_size und chunk_overlap festgelegt, um die Größe der Chunks und die Überlappung zwischen den Chunks anzugeben.\n",
    "\n",
    "Anschließend wird eine Instanz der CharacterTextSplitter-Klasse erstellt und den Variablen chunk_size und chunk_overlap übergeben. Diese Klasse implementiert die Logik zum Aufteilen des Textes in Chunks.\n",
    "\n",
    "Schließlich wird die Methode split_text() der splitter-Instanz aufgerufen, um den Text in Chunks aufzuteilen. Das Ergebnis wird in der Variable docs gespeichert. Schließlich werden die Chunks mit print(docs) ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One machine can do the work of fifty ordinary humans. No machine can do the work of one extraordinary human.']\n"
     ]
    }
   ],
   "source": [
    "quote = 'One machine can do the work of fifty ordinary humans. No machine can do the work of one extraordinary human.'\n",
    "chunk_size = 24\n",
    "chunk_overlap = 3\n",
    "\n",
    "# Create an instance of the splitter class\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap)\n",
    "\n",
    "# Split the document and print the chunks\n",
    "docs = splitter.split_text(quote) \n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Words are flowing out', 'out like endless rain', 'rain into a paper cup,', 'they slither while they', 'they pass,', 'they slip away across', 'across the universe.']\n"
     ]
    }
   ],
   "source": [
    "quote = 'Words are flowing out like endless rain into a paper cup,\\nthey slither while they pass,\\nthey slip away across the universe.'\n",
    "chunk_size = 24\n",
    "chunk_overlap = 10\n",
    "\n",
    "# Create an instance of the splitter class\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_overlap = 10,\n",
    "    chunk_size=24\n",
    "\n",
    ")\n",
    "\n",
    "# Split the document and print the chunks\n",
    "docs = splitter.split_text(quote)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/\")\n",
    "data = loader.load()\n",
    "\n",
    "# Define variables\n",
    "chunk_size = 300\n",
    "chunk_overlap = 100\n",
    "\n",
    "# Split the HTML\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=['.'])\n",
    "\n",
    "docs = splitter.split_documents(data)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

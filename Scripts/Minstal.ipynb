{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader \n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory,ConversationSummaryMemory\n",
    "\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Öffne die JSON-Datei und lade den Inhalt\n",
    "with open('/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/api_token.json', 'r') as api_file:\n",
    "    api_token_file = json.load(api_file)\n",
    "\n",
    "# Extrahiere die Variable aus den Daten\n",
    "api_token = api_token_file['Hugging_face_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_text_splitters.character.RecursiveCharacterTextSplitter at 0x1483d2790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50, \n",
    "    length_function = len)\n",
    "text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/doc_1.pdf'\n",
    "loader = PyPDFLoader(filepath)\n",
    "chunks = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page content: \n",
      " Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.comNoam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.comNiki Parmar∗\n",
      "Google Research\n",
      "nikip@google.comJakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.comAidan N. Gomez∗ †\n",
      "University of Toronto\n",
      "aidan@cs.toronto.eduŁukasz Kaiser∗\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhin∗ ‡\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/doc_1.pdf', 'page': 0}\n",
      "----------------------------\n",
      "Page content: \n",
      " entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more parallelizable and requiring significantly\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
      "to-German translation task, improving over the existing best results, including\n",
      "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
      "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n",
      "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
      "best models from the literature. We show that the Transformer generalizes well to\n",
      "other tasks by applying it successfully to English constituency parsing both with\n",
      "large and limited training data.\n",
      "∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\n",
      "the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/doc_1.pdf', 'page': 0}\n",
      "----------------------------\n",
      "Page content: \n",
      " has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\n",
      "attention and the parameter-free position representation and became the other person involved in nearly every\n",
      "detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\n",
      "tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\n",
      "efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\n",
      "implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\n",
      "our research.\n",
      "†Work performed while at Google Brain.\n",
      "‡Work performed while at Google Research.\n",
      "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.arXiv:1706.03762v7  [cs.CL]  2 Aug 2023\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/doc_1.pdf', 'page': 0}\n",
      "----------------------------\n",
      "Page content: \n",
      " 1 Introduction\n",
      "Recurrent neural networks, long short-term memory [ 13] and gated recurrent [ 7] neural networks\n",
      "in particular, have been firmly established as state of the art approaches in sequence modeling and\n",
      "transduction problems such as language modeling and machine translation [ 35,2,5]. Numerous\n",
      "efforts have since continued to push the boundaries of recurrent language models and encoder-decoder\n",
      "architectures [38, 24, 15].\n",
      "Recurrent models typically factor computation along the symbol positions of the input and output\n",
      "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
      "states ht, as a function of the previous hidden state ht−1and the input for position t. This inherently\n",
      "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/doc_1.pdf', 'page': 1}\n",
      "----------------------------\n",
      "Page content: \n",
      " significant improvements in computational efficiency through factorization tricks [ 21] and conditional\n",
      "computation [ 32], while also improving model performance in case of the latter. The fundamental\n",
      "constraint of sequential computation, however, remains.\n",
      "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [ 2,19]. In all but a few cases [ 27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
      "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
      "Page_metadata: \n",
      " {'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/doc_1.pdf', 'page': 1}\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks[:5]:\n",
    "    print(\"Page content: \\n\", chunk.page_content),\n",
    "    print(\"Page_metadata: \\n\", chunk.metadata),\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardo/anaconda3/envs/llm_train/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05895749852061272, 0.05387335643172264, 0.008316715247929096, 0.0206805057823658, 0.0022009313106536865, -0.034434445202350616, 0.08473188430070877, 0.1077682226896286, 0.058957234025001526, -0.016638653352856636, 0.06211813539266586, -0.0740492045879364, -0.0303032286465168, 0.03807591274380684, -0.004251338075846434, -0.007986415177583694, 0.0031452886760234833, -0.07220274955034256, -0.01501194667071104, -0.07136189937591553, -0.08817413449287415, 0.0452018640935421, 0.009071135893464088, 0.041956428438425064, -0.0012928870273754, -0.014840386807918549, -0.03942627087235451, 0.007077477872371674, -0.036413680762052536, -0.042899180203676224, -0.04982227832078934, 0.009418361820280552, -0.022699205204844475, 0.010238043032586575, -0.00445396825671196, -0.07801611721515656, -0.070695661008358, -0.005806431174278259, 0.03875807300209999, 0.01204211637377739, -0.05325385555624962, -0.0963793396949768, -0.028097203001379967, -0.009883742779493332, 0.06731418520212173, 0.004278208594769239, 0.02124866470694542, -0.022914476692676544, -0.06625277549028397, -0.02348857931792736, 4.158759111305699e-05, 0.00964048970490694, -0.03294288367033005, 0.014496402814984322, 0.018593674525618553, 0.047485243529081345, -0.012361058965325356, 0.03878827765583992, 0.02369307167828083, -0.06135307252407074, -0.002361031249165535, -0.03253591060638428, -0.11364953964948654, 0.06236247345805168, 0.059831637889146805, 0.08645803481340408, -0.022679559886455536, 0.03328515589237213, 0.016969120129942894, -0.04824632778763771, -0.010130156762897968, -0.0021239817142486572, -0.06585216522216797, -0.04025018960237503, -0.021393608301877975, -0.02657456323504448, 0.046205248683691025, -0.044886842370033264, 0.034001607447862625, 0.05156944692134857, -0.006135378964245319, 0.001145144458860159, -0.09618978202342987, 0.029961099848151207, -0.007510695140808821, 0.015603425912559032, -0.042808204889297485, 0.043429456651210785, -0.019901875406503677, 0.07665636390447617, -0.01384327095001936, 0.034392017871141434, 0.07292252033948898, 0.0133975213393569, -0.07558221369981766, -0.03218085318803787, -0.05393291264772415, -0.016610195860266685, -0.10869736224412918, 0.23937205970287323, -0.020459236577153206, 0.014236437156796455, 0.02164141833782196, 0.09602873772382736, -0.010307742282748222, 0.01200162898749113, -0.018780171871185303, -0.04145337641239166, 0.048597563058137894, -0.005922127515077591, -0.06287381052970886, -0.03733189404010773, 0.013004820793867111, -0.009868098422884941, 0.048202723264694214, -0.02079993113875389, -0.08003193140029907, 0.005167827010154724, 0.00725804315879941, -0.014367008581757545, 0.06591780483722687, 0.04329393804073334, -0.06329438835382462, 0.014587262645363808, -0.003063279204070568, -0.03614052012562752, 0.03620026260614395, -4.612938114318177e-33, 0.0409914031624794, 0.004939346108585596, -0.006083912216126919, 0.043096765875816345, 0.0167239923030138, 0.09288540482521057, -0.03938951715826988, 0.004293610341846943, -0.05639263615012169, 0.0672842413187027, -0.16096237301826477, -0.0779045820236206, -0.03543432056903839, 0.0018369597382843494, 0.06707488000392914, 0.028946315869688988, 0.03300480917096138, 0.029375018551945686, -0.0051882704719901085, -0.027864258736371994, -0.01788497157394886, 0.1109727993607521, -0.04470197111368179, 0.04207243770360947, 0.011976080946624279, -0.08128233253955841, 0.008002789691090584, -0.07154875248670578, -0.06217927113175392, 0.033613819628953934, -0.01154992263764143, 0.027502810582518578, -0.07996906340122223, 0.002480847528204322, 0.02366090752184391, -0.09160154312849045, 0.06299559026956558, -0.004837492015212774, -0.0030987428035587072, -0.024675210937857628, 0.08662998676300049, 0.024653417989611626, -9.652456355979666e-05, -0.03318057581782341, -0.009754078462719917, 0.08528172969818115, 0.09049248695373535, -0.005956639070063829, 0.011446849443018436, 0.042310360819101334, 0.0035262685269117355, -0.01033497042953968, -0.07504887878894806, -0.012202832847833633, 0.03234664723277092, 0.025926638394594193, 0.019049691036343575, -0.012024185620248318, 0.05401187390089035, 0.01013104896992445, 0.04285314679145813, -0.040263108909130096, 0.013790000230073929, -0.06209595873951912, -0.009781830944120884, -0.033753663301467896, -0.02063378319144249, -0.03565194085240364, 0.05844387784600258, -0.0428612157702446, -0.05484124273061752, 0.0035845881793648005, 0.0965285524725914, -0.039651673287153244, -0.008388887159526348, -0.02007421851158142, 0.018253538757562637, 0.030845442786812782, -0.003916537389159203, -0.03722589462995529, -0.03793429955840111, -0.0366276390850544, 0.040177375078201294, 0.025641752406954765, 0.050752341747283936, 0.009178625419735909, 0.015644922852516174, -0.05116970092058182, 0.026423173025250435, -0.04617452621459961, -0.11185549944639206, 0.04559491202235222, 0.005629034712910652, 0.04989961162209511, 0.01582547090947628, 4.343787009520321e-33, -0.04824649542570114, 0.05515504628419876, -0.03658045455813408, 0.07717882096767426, -0.04245702549815178, -0.01731182262301445, -0.027591269463300705, 0.05471985787153244, 0.016260158270597458, 0.04789765179157257, 0.07744024693965912, -0.10876806825399399, 0.008191938512027264, -0.056485943496227264, 0.0007533782045356929, -0.019367031753063202, 0.06802394241094589, -0.018168283626437187, -0.07287456095218658, 0.0047272080555558205, -0.08330320566892624, -0.07571673393249512, -0.041829537600278854, 0.023495955392718315, -0.06861050426959991, 0.1004837229847908, -0.024190634489059448, 0.10863713920116425, -0.013029152527451515, 0.0865088626742363, 0.04757517948746681, -0.08774615824222565, -0.00682770274579525, 0.03047875314950943, 0.02873203717172146, 0.20470963418483734, 0.09231504052877426, 0.016746576875448227, -0.00757240504026413, 0.0051491581834852695, 0.042321279644966125, -0.025120457634329796, 0.02354445494711399, 0.13627475500106812, -0.04834604263305664, -0.012725894339382648, -0.004134716931730509, -0.007316081319004297, 0.08094491809606552, 0.030172914266586304, 0.025221839547157288, 0.03171887993812561, -0.025279255583882332, -0.05385499447584152, -0.017319928854703903, 0.02615794911980629, 0.03106723353266716, -0.018321603536605835, -0.03890589624643326, -0.024325508624315262, 0.03653610870242119, 0.018517831340432167, -0.004494012799113989, 0.060770463198423386, -0.008643320761620998, -0.034977179020643234, -0.04582889750599861, -0.018905285745859146, 0.005996147636324167, -0.01612183451652527, 0.06939784437417984, 0.003852604888379574, -0.0701839029788971, -0.08292588591575623, -0.026484305039048195, -0.08900762349367142, -0.022247757762670517, -0.013534908182919025, 0.0385512076318264, -0.039532650262117386, -0.05805931240320206, 0.019006885588169098, 0.0005042309057898819, -0.06959947198629379, -0.043609146028757095, 0.03509559854865074, 0.05783523619174957, -0.014005331322550774, -0.028270576149225235, 0.043782323598861694, -0.012300968170166016, 0.06069758161902428, 0.09069006890058517, -0.01602812483906746, 0.006933591794222593, -1.5034773426236825e-08, 0.05863410234451294, -0.024170150980353355, -0.026048174127936363, 0.06980574876070023, 0.06045081093907356, 0.006414224859327078, -0.05531464144587517, 0.012504199519753456, 0.04093146324157715, 0.028846364468336105, 0.01760147511959076, 0.005015002563595772, 0.023594560101628304, 0.0516316257417202, 0.0250548105686903, -0.05722063407301903, -0.12157945334911346, -0.00018272407760377973, -0.022113293409347534, -0.08405864983797073, -0.026487981900572777, 0.015580772422254086, -2.8786578695871867e-05, 0.023379845544695854, 0.0061817290261387825, 0.047046516090631485, -0.1017637699842453, 0.07688648253679276, 0.09898848831653595, -0.015477916225790977, 0.008368835784494877, 0.043241195380687714, -0.0442679338157177, 0.02451329305768013, -0.037223149091005325, -0.04206930100917816, -0.01472825463861227, 0.026079634204506874, -0.015963831916451454, 0.1360192447900772, -0.05150851234793663, 0.022148428484797478, 0.027097739279270172, -0.0014352109283208847, -0.06500371545553207, -0.020484279841184616, -0.04887637495994568, 0.0839962512254715, -0.0072325654327869415, -0.020550437271595, -0.06095936894416809, 0.06612943112850189, -0.00011498568346723914, 0.05219540372490883, 0.07801417261362076, 0.017105529084801674, 0.09189657866954803, 0.02236110344529152, -0.07054458558559418, 0.05508328601717949, 0.17235015332698822, -0.004390910267829895, 0.011533830314874649, -0.025606105104088783]\n",
      "Dimension of Embedding:  384\n"
     ]
    }
   ],
   "source": [
    "embedding = embedding_function.embed_documents(\"This is a test sentence.\")\n",
    "\n",
    "print(embedding[0])\n",
    "print(\"Dimension of Embedding: \", len(embedding[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(chunks, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks in DB: 48\n"
     ]
    }
   ],
   "source": [
    "print(\"Chunks in DB:\", db._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics , 19(2):313–330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference ,\\npages 152–159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing , 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304 , 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL , pages 433–440. ACL, July\\n2006.', metadata={'page': 11, 'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/doc_1.pdf'}),\n",
       " Document(page_content='of a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture', metadata={'page': 1, 'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/doc_1.pdf'}),\n",
       " Document(page_content='Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130 , 2017.\\n[23] Minh-Thang Luong, Quoc V . Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114 , 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025 , 2015.\\n11', metadata={'page': 10, 'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/doc_1.pdf'}),\n",
       " Document(page_content='[4]Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733 , 2016.\\n10', metadata={'page': 9, 'source': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/doc_1.pdf'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Write a summary of the first page of the document.\"\n",
    "retriever = db.as_retriever()\n",
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/riccardo/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.2', \n",
    "                     huggingfacehub_api_token=api_token,  \n",
    "                     model_kwargs={\"max_length\": 100})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQAWithSourcesChain(combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question', 'summaries'], template='Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \\nIf you don\\'t know the answer, just say that you don\\'t know. Don\\'t try to make up an answer.\\nALWAYS return a \"SOURCES\" part in your answer.\\n\\nQUESTION: Which state/country\\'s law governs the interpretation of the contract?\\n=========\\nContent: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\\nSource: 28-pl\\nContent: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\\n\\n11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\\n\\n11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\\n\\n11.9 No Third-Party Beneficiaries.\\nSource: 30-pl\\nContent: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\\nSource: 4-pl\\n=========\\nFINAL ANSWER: This Agreement is governed by English law.\\nSOURCES: 28-pl\\n\\nQUESTION: What did the president say about Michael Jackson?\\n=========\\nContent: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\\nSource: 0-pl\\nContent: And we won’t stop. \\n\\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \\n\\nLet’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \\n\\nLet’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \\n\\nWe can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \\n\\nOfficer Mora was 27 years old. \\n\\nOfficer Rivera was 22. \\n\\nBoth Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\\nSource: 24-pl\\nContent: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \\n\\nAnd I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\n\\nThese steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \\n\\nBut I want you to know that we are going to be okay.\\nSource: 5-pl\\nContent: More support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\n\\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.\\nSource: 34-pl\\n=========\\nFINAL ANSWER: The president did not mention Michael Jackson.\\nSOURCES:\\n\\nQUESTION: {question}\\n=========\\n{summaries}\\n=========\\nFINAL ANSWER:'), llm=HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.2', huggingfacehub_api_token='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', model_kwargs={'max_length': 100}, model='mistralai/Mistral-7B-Instruct-v0.2', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>)), document_prompt=PromptTemplate(input_variables=['page_content', 'source'], template='Content: {page_content}\\nSource: {source}'), document_variable_name='summaries'), retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x28d53a590>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",  \n",
    "    retriever = retriever\n",
    "    )\n",
    "\n",
    "qa_with_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How are the writer of the document.',\n",
       " 'answer': ' The writers of the document are Mitchell P Marcus, Mary Ann Marcinkiewicz, Beatrice Santorini, David McClosky, Eugene Charniak, Mark Johnson, Ankur Parikh, Oscar Täckström, Dipanjan Das, Jakob Uszkoreit, Romain Paulus, Caiming Xiong, Richard Socher, Slav Petrov, Leon Barrett, Romain Thibaux, Dan Klein.\\n',\n",
       " 'sources': '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/doc_1.pdf'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How are the writer of the document.\"\n",
    "qa_with_sources.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who won the FIFA World Cup in the year 1994? \"\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, temperature=0.5, huggingfacehub_api_token=api_token, \n",
    "    model_kwargs={\"max_length\": 100}\n",
    ")\n",
    "\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50, \n",
    "    length_function = len)\n",
    "\n",
    "\n",
    "filepath = '/Users/riccardo/Desktop/Repositorys_Github/LLM/Docs/storytelling-with-data-cole-nussbaumer-knaflic.pdf'\n",
    "loader = PyPDFLoader(filepath)\n",
    "chunks = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embedding = embedding_function.embed_documents(\"This is a test sentence.\")\n",
    "db = Chroma.from_documents(chunks, embedding_function)\n",
    "query = \"Write a summary of the first page of the document.\"\n",
    "retriever = db.as_retriever()\n",
    "retriever.get_relevant_documents(query)\n",
    "llm = HuggingFaceHub(repo_id='mistralai/Mixtral-8x7B-Instruct-v0.1', \n",
    "                     huggingfacehub_api_token=api_token,  \n",
    "                     model_kwargs={\"max_length\": 100})\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",  \n",
    "    retriever = retriever\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Give me the title of the book.\"\n",
    "print(qa_with_sources.invoke(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

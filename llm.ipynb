{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Ã–ffne die JSON-Datei und lade den Inhalt\n",
    "with open('api_token.json', 'r') as api_file:\n",
    "    api_token_file = json.load(api_file)\n",
    "\n",
    "# Extrahiere die Variable aus den Daten\n",
    "api_token = api_token_file['Hugging_face_token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(repo_id='mistralai/Mistral-7B-Instruct-v0.2', huggingfacehub_api_token=api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Where is Langchain?'\n",
    "output = llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where is Langchain?\n",
      "\n",
      "Langchain is a decentralized language learning platform built on the Ethereum blockchain. It is not a physical location, but rather a digital ecosystem where users can access language learning resources, connect with language partners, and earn rewards for their learning progress.\n",
      "\n",
      "How does Langchain work?\n",
      "\n",
      "Langchain uses smart contracts to facilitate language learning and reward users for their progress. Users can access a variety of language learning resources, such as videos, articles, and interactive exercises,\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are an artificial intelligence assistant, answer the question. {question}\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How does LangChain make LLM application development easier?',\n",
       " 'text': 'You are an artificial intelligence assistant, answer the question. How does LangChain make LLM application development easier?\\n\\nLangChain is a language model chain that utilizes multiple language models to generate more accurate and contextually relevant responses. It makes LLM (Large Language Model) application development easier in several ways:\\n\\n1. Improved Accuracy: By chaining multiple language models, LangChain can generate more accurate responses by leveraging the strengths of each model. This reduces the need for extensive fine-tuning and manual intervention in the development process.\\n2. Contextual Understanding:'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"How does LangChain make LLM application development easier?\"\n",
    "llm_chain.invoke(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
